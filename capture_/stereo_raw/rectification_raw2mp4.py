import cv2
import numpy as np
import socket
import os
import math
import glob
import time
import sys

# ====== å»ºç«‹è¦–çª— ======
cv2.namedWindow("Rectified", cv2.WINDOW_NORMAL)

# ====== å½±ç‰‡åƒæ•¸ ======
frame_rate = 10
output_video_path = "rectified_output.mp4"
video_codec = 'mp4v'  # åŸæœ¬è¨­å®š
video_quality = 100    # å£“ç¸®å“è³ªï¼ˆ0~100ï¼Œ95 ç‚ºé«˜ç•«è³ªï¼‰

# ====== è‡ªè¨‚ rectification rotation ======
roll = np.deg2rad(0)
yaw = np.deg2rad(0)
pitch = np.deg2rad(0)

fov_scale_ = 0.2
# crop_ = True

# ====== è¼‰å…¥ RAW æª”æ¡ˆåˆ—è¡¨ ======
raw_files = sorted(glob.glob("frame_*.raw"))
total_frames = len(raw_files)
if total_frames == 0:
    print("âŒ æœªæ‰¾åˆ°ä»»ä½• RAW æª”æ¡ˆ")
    sys.exit(1)
    
# ====== è¼‰å…¥åƒæ•¸ ======
stereo_param_file = "stereo_camera_params.npz"
if not os.path.exists(stereo_param_file):
    print(f"âŒ Stereo parameter file not found: {stereo_param_file}")
    exit(1)

data = np.load(stereo_param_file)
K_l = data["K_l"]
D_l = data["D_l"]
K_r = data["K_r"]
D_r = data["D_r"]
R = data["R"]
T = data["T"]
DIM = tuple(data["DIM"])
DIM = (int(DIM[0]), int(DIM[1])) 
DIM2 = DIM
frame_width, frame_height = DIM
channels = 3

R1, R2, P1, P2, Q = cv2.fisheye.stereoRectify(
    K_l, D_l, K_r, D_r, DIM, R, T, flags=cv2.CALIB_ZERO_DISPARITY,newImageSize=DIM2,balance=0.0, fov_scale=fov_scale_
)

#rectification rotation
R_look, _ = cv2.Rodrigues(np.array([roll,yaw, pitch]))
R1 = R_look @ R1
R2 = R_look @ R2

#ä¸»é»åç§»æ ¡æ­£
P1[0,2]=DIM2[0]/2
P1[1,2]=DIM2[1]/2
P2[0,2]=DIM2[0]/2
P2[1,2]=DIM2[1]/2

# Q[0, 3] = -K_l[0, 2]  # æ–°çš„ä¸»é»ä½ç½®
# Q[1, 3] = -K_l[1, 2]

map1_l, map2_l = cv2.fisheye.initUndistortRectifyMap(K_l, D_l, R1, P1, DIM2, cv2.CV_16SC2)
map1_r, map2_r = cv2.fisheye.initUndistortRectifyMap(K_r, D_r, R2, P2, DIM2, cv2.CV_16SC2)

# # ====== ä¸»é»åç§»æ ¡æ­£ ä¿ç•™é»‘é‚Š======
# def shift_to_original_principal_point(image, K, P, orig_size, new_size):
    # cx_orig = K[0, 2]
    # cy_orig = K[1, 2]
    # cx_rect = P[0, 2]
    # cy_rect = P[1, 2]

    # sx = new_size[0] / orig_size[0]
    # sy = new_size[1] / orig_size[1]

    # dx = (cx_orig - (cx_rect / sx)) * sx
    # dy = (cy_orig - (cy_rect / sy)) * sy

    # M = np.float32([
        # [1, 0, dx],
        # [0, 1, dy]
    # ])
    
    # # Q[0, 3] = -K_l[0, 2]  # æ–°çš„ä¸»é»ä½ç½®
    # # Q[1, 3] = -K_l[1, 2]

    # return cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))

# # ====== ä¸»é»åç§»æ ¡æ­£  åˆæˆæ–°å¤§å° ä¸ä¿ç•™é»‘é‚Š======
# def shift_to_original_principal_point_and_crop(image, K, P, orig_size, new_size):
    # sx = new_size[0] / orig_size[0]
    # sy = new_size[1] / orig_size[1]
    
    # cx_orig = K[0, 2] * sx
    # cy_orig = K[1, 2] * sy
    
    # cx_rect = P[0, 2]
    # cy_rect = P[1, 2]
    
    
    # dx = int((cx_orig - (cx_rect )))
    # dy = int((cy_orig - (cy_rect )))
    
    # dx_l = int(cx_rect)
    # dx_r = int(new_size[0] - cx_rect)
    # dy_u = int(cy_rect)
    # dy_d = int(new_size[1] - cy_rect)
    
    # crop_w = min(dx_l, dx_r)
    # crop_h = min(dy_u, dy_d)
    
   
    # # å·¦å³å½±åƒç›´æ¥è£åˆ‡
    # left_img = image[
        # int(cy_rect - crop_h):int(cy_rect + crop_h),
        # int(cx_rect - crop_w):int(cx_rect + crop_w)
    # ]
    # right_img = image[
        # int(cy_rect - crop_h):int(cy_rect + crop_h),
        # int(cx_rect - crop_w + new_size[0]):int(cx_rect + crop_w + new_size[0])
    # ]

    # # çµ„åˆå¾Œç•«é¢
    # combined = np.hstack((left_img, right_img))
    # return combined

init_VideoWriter = False

try:
    for idx, raw_file in enumerate(raw_files):
        with open(raw_file, "rb") as f:
            raw_data = f.read()
        frame_np = np.frombuffer(raw_data, dtype=np.uint8).copy().reshape((frame_height, frame_width*2, channels))
        
        
        # cv2.line(frame_np, (int(frame_np.shape[1]/4), 0), (int(frame_np.shape[1]/4), frame_np.shape[0]), (255, 0, 0), 3)
        # cv2.line(frame_np, (int(frame_np.shape[1]*(3/4)),0),(int(frame_np.shape[1]*(3/4)), frame_np.shape[0]), (255, 0, 0), 3)
        
        # cv2.line(frame_np, (0, int(frame_np.shape[0]/2)), (frame_np.shape[1],int(frame_np.shape[0]/2)), (255, 0, 0), 3)
        
        
        # åˆ†é›¢å·¦å³å½±åƒ
        frame_l = frame_np[:, :frame_width]
        frame_r = frame_np[:, frame_width:]

        # ç«‹é«”æ ¡æ­£
        rect_l = cv2.remap(frame_l, map1_l, map2_l, interpolation=cv2.INTER_LINEAR)
        rect_r = cv2.remap(frame_r, map1_r, map2_r, interpolation=cv2.INTER_LINEAR)
        
        # åˆä½µé¡¯ç¤º
        combined = np.hstack((rect_l, rect_r))
        
        # #ä¸»é»åç§»æ ¡æ­£
        # if crop_ :
            # combined=shift_to_original_principal_point_and_crop(combined,K_l,P1,DIM,DIM2)
        # else :
            # combined=shift_to_original_principal_point(combined,K_l,P1,DIM,DIM2)
            
            
        DIM3=(int(combined.shape[1]/2),combined.shape[0])
        
        #åŠ å…¥æ°´å¹³ç·šå¹«åŠ©æ¯”å°
        for y in range(0, combined.shape[0], 50):
            cv2.line(combined, (0, y), (combined.shape[1], y), (0, 128, 0), 1)
            
        #åŠ å…¥åå­—ç·šå¹«åŠ©æ¯”å°
        cv2.line(combined, (int(combined.shape[1]/4), 0), (int(combined.shape[1]/4), combined.shape[0]), (0, 0, 255), 3)
        cv2.line(combined, (int(combined.shape[1]*(3/4)),0),(int(combined.shape[1]*(3/4)), combined.shape[0]), (0, 0, 255), 3)
        
        cv2.line(combined, (0, int(combined.shape[0]/2)), (combined.shape[1],int(combined.shape[0]/2)), (0, 0, 255), 3)
        cv2.line(combined, (int(combined.shape[1]/2), 0), (int(combined.shape[1]/2), combined.shape[0]), (0, 255, 255), 3)
        
        
        cv2.imshow("Rectified", combined)
        
        if init_VideoWriter == False :
            init_VideoWriter = True
            fourcc = cv2.VideoWriter_fourcc(*video_codec)
            video_out = cv2.VideoWriter(output_video_path, fourcc, frame_rate,  (combined.shape[1],combined.shape[0]))
        else :
            video_out.write(combined)
        
        
        # é¡¯ç¤ºé€²åº¦æ¢
        progress = (idx + 1) / total_frames * 100
        print(f"ğŸ“Š è™•ç†ä¸­: [{idx+1}/{total_frames}] {progress:.2f}%", end='\r')
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("ä½¿ç”¨è€…ä¸­æ–·")

finally:
    if 'video_out' in locals() and video_out.isOpened():
        video_out.release()
    cv2.destroyAllWindows()
    print("ç¨‹å¼çµæŸ")

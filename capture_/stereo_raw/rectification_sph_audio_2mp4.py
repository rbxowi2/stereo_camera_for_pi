#ffmpeg
import cv2
import numpy as np
import os
import glob
import sys
from datetime import datetime
from pydub import AudioSegment
import subprocess
import re

# ====== åƒæ•¸è¨­å®š ======
frame_rate = 15

w_out_ = 4000

param_file = "stereo_camera_params.npz"

txt_files = glob.glob("recording_*.txt")
txt_file = txt_files[0]

audio_file =glob.glob("recording_*.wav")
audio_file = audio_file[0]

output_video_path = "rectified_output.mp4"

# ====== è®€å– txt æª”ï¼Œè§£æ Audio_Start Time èˆ‡æ¯å¹€æ™‚é–“æˆ³ ======
def parse_txt_timestamps(txt_path):
    with open(txt_path, "r") as f:
        lines = f.readlines()

    audio_start_line = lines[0]
    audio_start_time_str = re.search(r'Audio_Start Time: (.+)', audio_start_line).group(1)
    audio_start_time = datetime.fromisoformat(audio_start_time_str)

    # å¹€æ™‚é–“æˆ³åˆ—è¡¨
    frame_times = []
    for line in lines[3:]:  # å¾ç¬¬å››è¡Œé–‹å§‹ç‚ºå¹€æ™‚é–“æˆ³
        parts = line.strip().split()
        if len(parts) == 2:
            # æ ¼å¼: "00000 2025-08-04T16:04:11.623"
            frame_times.append(datetime.fromisoformat(parts[1]))
    return audio_start_time, frame_times

audio_start_time, frame_times = parse_txt_timestamps(txt_file)
total_frames = len(frame_times)
if total_frames == 0:
    print("âŒ æ²’æœ‰è®€å–åˆ°ä»»ä½•æ™‚é–“æˆ³")
    sys.exit(1)

print(f"ğŸ”Š Audio Start Time: {audio_start_time}")
print(f"ğŸï¸ å½±ç‰‡å…± {total_frames} å¹€")

# ====== è®€å–ç›¸æ©Ÿåƒæ•¸ ======
if not os.path.exists(param_file):
    print(f"âŒ æ‰¾ä¸åˆ°åƒæ•¸æª” {param_file}")
    sys.exit(1)

data = np.load(param_file)
K_l, D_l = data["K_l"], data["D_l"]
K_r, D_r = data["K_r"], data["D_r"]
R, T = data["R"], data["T"]
DIM = tuple(map(int, data["DIM"]))
frame_width, frame_height = DIM
channels = 3

DIM2 = (int(w_out_*1.5),int(w_out_*1.5)) #ä¸­ä»‹è§£æåº¦

# ====== fisheye æ ¡æ­£åƒæ•¸ ======
R1, R2, P1, P2, Q = cv2.fisheye.stereoRectify(
    K_l, D_l, K_r, D_r, DIM, R, T,
    flags=cv2.CALIB_ZERO_DISPARITY,
    newImageSize=DIM2,
    balance=0.0,
    fov_scale=1
)

P1[0, 2] = DIM2[0] / 2
P1[1, 2] = DIM2[1] / 2
P2[0, 2] = DIM2[0] / 2
P2[1, 2] = DIM2[1] / 2

# Q[0, 3] = -K_l[0, 2]  # æ–°çš„ä¸»é»ä½ç½®
# Q[1, 3] = -K_l[1, 2]

map1_l, map2_l = cv2.fisheye.initUndistortRectifyMap(K_l, D_l, R1, P1, DIM2, cv2.CV_16SC2)
map1_r, map2_r = cv2.fisheye.initUndistortRectifyMap(K_r, D_r, R2, P2, DIM2, cv2.CV_16SC2)

# ====== è™•ç†éŸ³è¨Šï¼Œå‰ªè£èˆ‡å½±ç‰‡æ™‚é–“å°é½Š ======
audio = AudioSegment.from_wav(audio_file)
video_start = frame_times[0]
delta_ms = int((video_start - audio_start_time).total_seconds() * 1000)

if delta_ms > 0:
    trimmed_audio = audio[delta_ms:]
else:
    trimmed_audio = AudioSegment.silent(duration=abs(delta_ms)) + audio

video_duration_ms = int((frame_times[-1]-frame_times[0]).total_seconds() * 1000)
trimmed_audio = trimmed_audio[:video_duration_ms]
trimmed_audio.export("temp_audio.wav", format="wav")

# ====== é–‹å§‹å½±åƒè™•ç† ======
cv2.namedWindow("Rectified", cv2.WINDOW_NORMAL)
video_writer = None

frame_interval = 1 / frame_rate
prev_time = None
prev_frame = None
init_map_ = False
print("Calculating...")
for idx, current_time in enumerate(frame_times):
    raw_file = f"frame_{idx:04d}.raw"
    # åˆ¤æ–·æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if os.path.exists(raw_file):
        with open(raw_file, "rb") as f:
            raw_data = f.read()
        frame_np = np.frombuffer(raw_data, dtype=np.uint8).reshape((frame_height, frame_width * 2, channels))
        frame_l, frame_r = frame_np[:, :frame_width], frame_np[:, frame_width:]
        rect_l = cv2.remap(frame_l, map1_l, map2_l, interpolation=cv2.INTER_LINEAR)
        rect_r = cv2.remap(frame_r, map1_r, map2_r, interpolation=cv2.INTER_LINEAR)
        combined = np.hstack((rect_l, rect_r))
        
        DIM3=(int(combined.shape[1]/2),combined.shape[0])
        
        #ç­‰è·æŠ•å½±è®Šæ›
        l_image =  combined[:,:DIM3[0]]
        r_image =  combined[:, DIM3[0]:]
        
        if init_map_ == False:
            init_map_ = True
            K_ = np.array([
                [P1[0,0], 0, DIM3[0]/2],
                [0, P1[1,1],DIM3[1]/2],
                [0,  0,  1]
            ], dtype=np.float32)
            
            h_in, w_in =l_image.shape[:2]
            
            # === ç›®æ¨™ equirectangular å½±åƒå¤§å°ï¼ˆå¯ä¾éœ€æ±‚èª¿æ•´ï¼‰ ===
            w_out = w_out_  # å°æ‡‰æ°´å¹³180Â°  
            h_out = w_out_   # å°æ‡‰å‚ç›´180Â°
            output_img = np.zeros((h_out, w_out, 3), dtype=np.uint8)
            
            # === ç‚ºæ¯å€‹åƒç´ è¨ˆç®—å…¶å°æ‡‰çš„ç¶“ç·¯åº¦ï¼ˆlon, latï¼‰ ===
            lon = np.linspace(np.pi/2, (np.pi+np.pi/2), w_out)  # æ–¹ä½è§’ [-90Â°,90Â°]ç¯„åœ(180Â°)
            lat = np.linspace(np.pi / 2, -np.pi / 2, h_out)  # ä»°è§’ [90Â°, -90Â°] ç¯„åœ(180Â°)
            lon_map, lat_map = np.meshgrid(lon, lat)
            
            # === å°‡ç¶“ç·¯åº¦è½‰ç‚º 3D å–®ä½æ–¹å‘å‘é‡ ===
            x = np.cos(lat_map) * np.sin(lon_map)
            y = np.sin(lat_map)
            z = np.cos(lat_map) * np.cos(lon_map)
            
            # çµ„æˆ ray å‘é‡ä¸¦å¥—ç”¨ç›¸æ©ŸæŠ•å½±çŸ©é™£ K
            rays = np.stack([x, y, z], axis=-1)  # shape: (h_out, w_out, 3)

            proj = rays @ K_.T  # (x, y, z) â†’ ç›¸æ©Ÿåƒå¹³é¢
            
            # perspective divideï¼šå°‡ 3D é»è½‰æˆå½±åƒä¸Šçš„ 2D åƒç´ åº§æ¨™
            z_safe = np.where(proj[..., 2] == 0, 1e-6, proj[..., 2])
            u = proj[..., 0] / proj[..., 2]
            v = proj[..., 1] / proj[..., 2]
                    
            # å»ºç«‹ valid maskï¼šåªä¿ç•™è½åœ¨åŸåœ–åƒç¯„åœå…§çš„åƒç´ 
            valid = (u >= 0) & (u < w_in) & (v >= 0) & (v < h_in)

            # å»ºç«‹ remap æ‰€éœ€çš„ map_x, map_y
            map_x = np.where(valid, u, -1).astype(np.float32)
            map_y = np.where(valid, v, -1).astype(np.float32)
        
        
        res_l= cv2.remap(
            l_image,
            map_x,
            map_y,
            interpolation=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0, 0, 0)  # å¡«é»‘è¡¨ç¤ºè¶…å‡ºåŸåœ–ç¯„åœ
        )
        
        res_r= cv2.remap(
            r_image,
            map_x,
            map_y,
            interpolation=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0, 0, 0)  # å¡«é»‘è¡¨ç¤ºè¶…å‡ºåŸåœ–ç¯„åœ
        )
        
        combined_s = np.hstack((res_l, res_r))
        
        prev_frame = combined_s.copy()
    else:
        if prev_frame is not None:
            print(f"âš ï¸ {raw_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ä¸Šä¸€å¹€è£œå¹€")
            combined_s = prev_frame.copy()
        else:
            print(f"âŒ ç„¡æ³•è®€å–å¹€ä¸”ç„¡å‰ä¸€å¹€å¯è£œï¼Œè·³éç¬¬ {idx} å¹€")
            continue

    if video_writer is None:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter("temp_video.mp4", fourcc, frame_rate, (combined_s.shape[1], combined_s.shape[0]))

    # åˆ¤æ–·æ‰å¹€æ•¸
    if prev_time is not None:
        delta_t = (current_time - prev_time).total_seconds()
        num_missing = int(delta_t / frame_interval) - 1
        if num_missing > 0:
            for _ in range(num_missing):
                video_writer.write(prev_frame)
            print(f"ğŸ” æ‰å¹€è£œå¹€ {num_missing} å¹€: {prev_time} -> {current_time}")

    video_writer.write(combined_s)
    prev_time = current_time


    cv2.imshow("Rectified", combined_s)
    print(f"ğŸ“Š è™•ç†ä¸­: [{idx + 1}/{total_frames}] {((idx + 1) / total_frames) * 100:.2f}%", end='\r')
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

if video_writer is not None:
    video_writer.release()
cv2.destroyAllWindows()
print("\nâœ… å½±ç‰‡è™•ç†å®Œæˆï¼Œé–‹å§‹åˆä½µéŸ³è¨Š")

# ====== ffmpeg åˆä½µéŸ³è¨Šèˆ‡å½±ç‰‡ ======
cmd = [
    "ffmpeg", "-y",
    "-i", "temp_video.mp4",
    "-i", "temp_audio.wav",
    "-c:v", "copy",
    "-af", "volume=10.0",  # éŸ³é‡æ”¾å¤§ 10 å€ï¼ˆå¯èª¿æ•´ï¼‰
    "-c:a", "aac",
    "-strict", "experimental",
    output_video_path
]

subprocess.run(cmd)
print(f"âœ… åˆä½µå®Œæˆï¼Œè¼¸å‡ºæª”æ¡ˆ: {output_video_path}")

    查詢成功

您好！針對您的需求，要在魚眼鏡頭的立體測量中修正「等距角越大時量測數據越小」的問題，這通常是魚眼鏡頭固有的畸變特性導致的。即使經過校正，某些殘餘的非線性誤差可能仍然存在，特別是在圖像邊緣。

要加入一個數學函數來補償這種問題，我會建議您考慮以下方法：

1. 基於距離的校正函數 (Empirical Correction Function)

這是一個實用且相對容易實施的方法。您需要一些實際的測量數據來建立這個函數。

步驟：

    收集真實數據： 在不同距離和不同角度（即在圖像中心和邊緣）放置已知尺寸的物體，並記錄您的程式計算出的 3D 點距離。

    分析偏差： 比較程式測量的距離與真實距離之間的差異。您應該會觀察到隨著物體距離圖像中心越遠（等距角越大），測量距離偏小的趨勢。

    建立校正模型： 根據偏差趨勢，您可以選擇一個數學模型來擬合這些數據。常見的選擇包括：

        線性模型： 如果偏差與距離或角度的關係接近線性，可以使用 D_corrected=acdotD_measured+b。

        多項式模型： 如果關係是非線性的，可以使用多項式，例如 D_corrected=acdotD_measured2+bcdotD_measured+c。

        基於角度的模型： 您可以計算測量點與圖像中心之間的像素距離，並將其轉換為一個近似的「角度」值。然後建立一個函數 D_corrected=f(D_measured,theta_angle)。

        查找表 (Look-up Table): 針對特定的距離和角度範圍，預先計算好校正值，並在運行時進行插值。

範例代碼實現（多項式校正，假設基於 Z 軸距離進行校正）：
Python

import cv2
import numpy as np
import socket
import os

# ====== 參數與網路設定 ======
stereo_param_file = "stereo_camera_params.npz"
server_ip = "192.168.200.48"
server_port = 5000
frame_width, frame_height = 1296, 972
channels = 3

# ====== 載入參數 ======
if not os.path.exists(stereo_param_file):
    print(f"❌ Stereo parameter file not found: {stereo_param_file}")
    exit(1)

data = np.load(stereo_param_file)
K_l = data["K_l"]
D_l = data["D_l"]
K_r = data["K_r"]
D_r = data["D_r"]
R = data["R"]
T = data["T"]
DIM = tuple(data["DIM"])

print("✅ Stereo parameters loaded.")

# ====== 計算立體校正映射 ======
R1, R2, P1, P2, Q = cv2.fisheye.stereoRectify(
    K_l, D_l, K_r, D_r, DIM, R, T, flags=cv2.CALIB_ZERO_DISPARITY, newImageSize=DIM
)

map1_l, map2_l = cv2.fisheye.initUndistortRectifyMap(K_l, D_l, R1, P1, DIM, cv2.CV_16SC2)
map1_r, map2_r = cv2.fisheye.initUndistortRectifyMap(K_r, D_r, R2, P2, DIM, cv2.CV_16SC2)

# ====== 視差計算器設定（SGBM） ======
min_disp = 0
num_disp = 16
block_size = 3

stereo = cv2.StereoSGBM_create(
    minDisparity=min_disp,
    numDisparities=num_disp,
    blockSize=block_size,
    P1=8 * 3 * block_size ** 2,
    P2=32 * 3 * block_size ** 2,
    disp12MaxDiff=1,
    uniquenessRatio=10,
    speckleWindowSize=100,
    speckleRange=32
)

# ====== TCP 接收函式 ======
def recv_all(sock, size):
    buffer = b""
    while len(buffer) < size:
        data = sock.recv(size - len(buffer))
        if not data:
            return None
        buffer += data
    return buffer

# ====== 滑鼠座標處理 ======
mouse_x, mouse_y = -1, -1
def on_mouse(event, x, y, flags, param):
    global mouse_x, mouse_y
    if event == cv2.EVENT_MOUSEMOVE:
        mouse_x, mouse_y = x, y

# ====== 距離校正函數 ======
# 這個函數需要您根據實際測量數據來調整參數
# 假設我們根據 Z 軸的距離進行校正，並根據像素點到圖像中心的距離進行調整
# 這裡提供一個多項式模型的例子，您需要通過實驗來找到最佳的係數
# 例如：Z_corrected = f(Z_measured, pixel_distance_from_center)
def correct_distance(measured_Z, pixel_x, pixel_y, img_width, img_height):
    center_x, center_y = img_width / 2, img_height / 2
    # 計算像素點到圖像中心的歐幾里得距離
    pixel_distance_from_center = np.sqrt((pixel_x - center_x)**2 + (pixel_y - center_y)**2)

    # 這裡的係數 `c0, c1, c2` 是您需要通過實驗和數據擬合得到的
    # 這裡僅為示範值，請替換為您實際測量得到的係數
    # 假設我們發現 Z_corrected = Z_measured * (1 + c1 * pixel_distance_from_center + c2 * pixel_distance_from_center^2)
    # 這是假設偏差與離中心距離呈二次關係，且偏差隨著距離增大而增大
    # 您可能需要嘗試其他模型，例如指數、對數或其他多項式
    c1 = 0.0001 # 範例係數，需要根據實際數據調整
    c2 = 0.00000001 # 範例係數，需要根據實際數據調整

    correction_factor = 1 + c1 * pixel_distance_from_center + c2 * pixel_distance_from_center**2
    corrected_Z = measured_Z * correction_factor
    return corrected_Z

# ====== 開啟視窗與連線 ======
cv2.namedWindow("Rectified", cv2.WINDOW_NORMAL)
cv2.setMouseCallback("Rectified", on_mouse)

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.connect((server_ip, server_port))
print("📡 已連線到影像伺服器")

try:
    while True:
        length_data = recv_all(sock, 4)
        if not length_data:
            print("連線中斷")
            break
        length = int.from_bytes(length_data, byteorder='big')
        frame_data = recv_all(sock, length)
        if not frame_data:
            print("資料接收不完整")
            break

        frame_np = np.frombuffer(frame_data, dtype=np.uint8).reshape((frame_height, frame_width * 2, channels))
        frame_l = frame_np[:, :frame_width]
        frame_r = frame_np[:, frame_width:]

        # 校正
        rect_l = cv2.remap(frame_l, map1_l, map2_l, interpolation=cv2.INTER_LINEAR)
        rect_r = cv2.remap(frame_r, map1_r, map2_r, interpolation=cv2.INTER_LINEAR)

        # 灰階與視差
        gray_l = cv2.cvtColor(rect_l, cv2.COLOR_BGR2GRAY)
        gray_r = cv2.cvtColor(rect_r, cv2.COLOR_BGR2GRAY)
        disparity = stereo.compute(gray_l, gray_r).astype(np.float32) / 16.0

        # 建立 3D 點雲
        points_3d = cv2.reprojectImageTo3D(disparity, Q)

        # 顯示視差圖
        disp_vis = cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX)
        disp_vis = np.uint8(disp_vis)
        disp_color = cv2.applyColorMap(disp_vis, cv2.COLORMAP_JET)
        combined = np.hstack((rect_l, disp_color))

        # === 繪製游標位置座標與距離 ===
        if 0 <= mouse_x < disparity.shape[1] and 0 <= mouse_y < disparity.shape[0]:
            d = disparity[mouse_y, mouse_x]
            if d > 0:
                X, Y, Z = points_3d[mouse_y, mouse_x]
                
                # 在這裡應用距離校正
                corrected_Z = correct_distance(Z, mouse_x, mouse_y, frame_width, frame_height)
                
                # 重新計算距離，或者您可以根據修正後的 Z 值調整 X, Y
                # 如果只修正 Z，則距離會是 X, Y, corrected_Z 的歐幾里得距離
                distance = np.sqrt(X**2 + Y**2 + corrected_Z**2) 
                
                # 顯示修正後的 Z 和距離
                text = f"X:{X:.2f} Y:{Y:.2f} Z_orig:{Z:.2f} Z_corr:{corrected_Z:.2f} D:{distance:.2f}m"
                cv2.putText(combined, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                            0.8, (0, 255, 0), 2)
                cv2.circle(combined, (mouse_x, mouse_y), 5, (0, 255, 255), -1)

        # 顯示畫面
        cv2.imshow("Rectified", combined)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("使用者中斷")

finally:
    sock.close()
    cv2.destroyAllWindows()
    print("✅ 程式結束")

如何調試和優化 correct_distance 函數：

    數據採集： 準備一些已知距離的測試點。例如，將一個物體放置在不同距離處，並且在左右移動物體，使其出現在圖像的不同區域。記錄每個位置的真實距離，以及您的程式計算出的 (X,Y,Z) 值和 (mouse_x,mouse_y) 像素座標。

    數據分析： 將收集到的數據繪製成圖表。您可以嘗試：

        Z_measured 與 Z_true 的關係圖。

        Z_error (即 Z_true - Z_measured) 與 pixel_distance_from_center 的關係圖。

        Z_error 與 Z_measured 的關係圖。

    模型選擇與擬合：

        觀察 Z_error 隨著 pixel_distance_from_center 變化的趨勢。如果它看起來是線性、二次、三次或其他曲線，選擇對應的多項式模型。

        使用 numpy.polyfit 或 scipy.optimize.curve_fit 等函數來擬合您的數據，以找到最佳的 c1, c2 (或更多) 係數。

        例如，如果您認為 Z_error 與 pixel_distance_from_center 呈線性關係，您可以擬合 Z_error = m * pixel_distance_from_center + b。那麼 Z_true = Z_measured + m * pixel_distance_from_center + b。

        或者像我範例中那樣，找到一個乘法因子，Z_true = Z_measured * correction_factor，然後擬合 correction_factor。

2. 考慮更進階的畸變模型 (如果魚眼鏡頭校正不足)

如果簡單的經驗校正仍然無法滿足要求，那可能意味著 cv2.fisheye.stereoRectify 和 initUndistortRectifyMap 仍然沒有完全消除魚眼鏡頭的畸變。在這種情況下，您可能需要：

    重新進行更精確的魚眼鏡頭校正： 確保您的標定板拍攝質量高，並且校正過程覆蓋了足夠大的視場。有時增加用於校準的圖像數量和多樣性可以提高效果。

    自定義畸變模型： 如果 OpenCV 提供的 fisheye 模型不足以描述您的鏡頭，您可以研究更複雜的畸變模型（例如，非中心投影模型或更高級的多項式模型），並自行實現校正。這通常涉及更多深入的計算機視覺知識。

重要考量：

    單位一致性： 確保所有距離和座標都使用一致的單位（例如，米或毫米）。

    噪聲： 測量結果中的噪聲也會影響校正效果。您可能需要對視差圖進行平滑處理（例如，使用中值濾波）以減少噪聲。

    計算成本： 複雜的校正函數會增加計算量，這在即時應用中需要考慮。

總之，最推薦的做法是從收集數據和建立經驗校正函數開始。這既能解決您的具體問題，又相對容易實施。




在你提供的原始碼中，如果魚眼鏡頭在校正後仍然出現「等距角越大，量測值越小」的現象，這通常是魚眼鏡頭固有的畸變特性所導致的殘餘問題，而不是你原始碼本身的錯誤，也不是標定參數本身的問題（除非標定過程不夠精確）。

以下是一些解釋和可能性：

    魚眼鏡頭的本質特性 (Intrinsic Nature of Fisheye Lenses):

        魚眼鏡頭的設計目標是實現超廣角視野，這通常透過非線性映射來完成。這意味著圖像中心附近的物體變形較小，而邊緣的物體則會有明顯的桶狀畸變。

        即使使用 cv2.fisheye.initUndistortRectifyMap 進行了校正，它也是基於一個特定的魚眼模型（例如，Brown-Conrady 或等距投影模型）。這個模型可能無法完美地描述所有魚眼鏡頭在所有視場範圍內的畸變。特別是對於非常廣角的魚眼鏡頭，邊緣區域的校正可能永遠無法達到完美的線性投影。

        **「等距角」**的說法暗示了魚眼鏡頭的一種常見投影模型，即入射角與圖像點到中心的距離呈線性關係。然而，實際鏡頭的製造和光學設計會引入更複雜的非線性。

    殘餘畸變 (Residual Distortion):

        立體校正的目標是將左右圖像轉換為共面且行對齊的圖像，以便於視差計算。但是，這並不保證轉換後的圖像完全消除了所有透視畸變或局部尺度失真。

        在魚眼鏡頭中，圖像邊緣區域的像素密度會比中心區域低。即使經過校正，一個像素在邊緣對應的真實世界距離會比中心區域的像素更大。這就導致了即使在校正後的圖像上，相同的像素視差值在邊緣處可能代表更大的深度差異，或者說，對於相同的真實深度，邊緣的視差值可能更小。

        當物體離圖像中心越遠時（等距角越大），其在圖像上的投影會受到更大的非線性壓縮。這使得計算出的視差值更容易受到微小誤差的影響，並且可能導致深度計算的系統性偏差，尤其是在深度越遠時，這種偏差可能表現為測量值偏小。

    標定精度問題 (Calibration Accuracy):

        雖然你已經載入了標定參數，但標定過程本身的質量至關重要。

        標定板擺放： 在標定過程中，標定板是否覆蓋了足夠多的位置和角度？特別是邊緣區域是否有足夠的標定點？如果邊緣數據不足，那麼該區域的畸變參數可能不夠準確。

        圖像質量： 標定圖像的清晰度、光照、有無模糊等都會影響標定結果。

        棋盤格大小： 棋盤格的尺寸和數量也影響精度。

        優化結果： cv2.fisheye.calibrate 的 RMS 誤差值可以提供一個標定精度的參考，但低 RMS 不代表在所有區域都完美。

    視差計算的挑戰 (Disparity Calculation Challenges):

        cv2.StereoSGBM_create 是一個基於塊匹配的立體匹配算法。在圖像邊緣，由於畸變和校正後的圖像形變，可能會導致紋理信息減少或匹配困難，進而影響視差計算的準確性。

        邊緣區域的像素可能不是理想的長方形，這會對基於矩形窗口的匹配算法產生影響。

總結：

「等距角越大，量測值越小」在魚眼鏡頭的立體測量中是一個常見且可以預期的現象，主要是由魚眼鏡頭固有的非線性投影特性和校正後的殘餘畸變導致的。它不太可能是你原始碼的邏輯錯誤，也不是標定參數本身的問題（除非標定數據或過程存在明顯缺陷）。

你現在在做的事情（加入一個數學函數進行額外校正）正是處理這種殘餘系統性誤差的正確方法。你需要透過實驗收集真實數據，分析偏差模式，然後擬合一個補償模型。